---
title: "17. Working with text"
output:
  html_document:
    includes:
      in_header: header.html    
    toc: true
    toc_float: true
    theme: flatly
    highlight: textmate
    css: mystyle.css
    number_sections: true
    pandoc_args: [
      "--number-offset", 17
    ]
---

```{r,echo=FALSE,message = FALSE, warning = FALSE}
rm(list=objects()) # start with a clean workspace
source("knitr_tweaks.R")
library(tidyverse,quietly = TRUE)
```

```{css,echo=FALSE}
h1{
  line-height: 100px;
}
h2{
  line-height: 80px;
}
h3{
  line-height: 60px;
}
```


Sometimes your data set is quite text heavy. This can be for a lot of different reasons. Maybe the raw data are actually taken from text sources (e.g., newspaper articles), or maybe your data set contains a lot of free responses to survey questions. Or maybe you just need to reorganise some of the text used to describe nominal scale variables. Regardless of what the reason is, youâ€™ll probably want to know a little bit about how to handle text in R. A few minor examples of this have appeared earlier in these notes (e.g., using `nchar()` to calculate the number of characters in a string). When I wrote *Learning Statistics with R* I included some notes on how to work with text using base R, but overall I've come to the view that the tidyverse approach provided via the **stringr** package is a little more coherent and less problematic for new users, so I'll take that approach here. 

## Preliminaries

- `print` 
- `cat`
- escaping

## Getting started

The data come from Experiment 1 in a [very cool paper](https://doi.org/10.1073/pnas.0707835105) by Simon Kirby, Hannah Cornish, and Kenny Smith. 

```{r, message=FALSE}
chains <- read_csv("./data/kirbyetal2008_exp1_wide.csv")
chain_3 <- chains %>% 
  filter(version == "chain3") %>%
  select(color,shape,motion,starts_with("name")) 
print(chain_3)

input <- chain_3$name_0
output <- chain_3$name_10
```

Excellent! I have a data set `r emo::ji("white_check_mark")` Next, I'll need a string manipulation package. **stringr** is loaded automatically with **tidyverse** so that's another `r emo::ji("white_check_mark")`. Time to get started! 

## Flatten strings

Our first job might be just to visually inspect the words that appear in the `output` of the iterated learning chain, and compare them to the words that were present in the `input`. To make things easier on ourselves, we'll use the `str_flatten()` function to *flatten* each of these vectors to a single string. We'll specify `collapse = ", "` so that the output takes the form of a nice comma-separated list of words

```{r}
input %>% str_flatten(collapse = ", ")
output %>% str_flatten(collapse = ", ")
```

## String length

The one of the first things I notice when looking at this output is that they're rather different in length. Even though there are 27 words in each list, it looks like the `output` words are shorter. We can check this by using the `str_length()` function to compute the length of each word. 

```{r}
input %>% str_length() 
output %>% str_length()
```

## Substrings

One thing I might be interested in, either for theoretical reasons (e.g., looking for meaningful prefixes) or practical ones (e.g., convenient plot labels) is extract a smaller subset of the string. A common example is to take the first three characters. We can do this using `str_sub()`

```{r}
output %>% str_sub(start = 1, end = 3)
```

A feature of `str_sub` that sometimes comes in handy is that you can specify negative values here to refer to the distance from the end of the string. If for instance I wanted to extract the last three characters in every word:

```{r}
output %>% str_sub(start = -3, end = -1)
```

## Duplication

I'm not sure why I would want it in this context, but we can duplicate strings using `str_dup()`

```{r}
output %>% str_dup(times = 3)
```

## Truncation and padding

Sometimes it is useful to ensure that every string has the same length. Again, this can be   quite useful when labelling data. For longer strings we might need to truncate it using `str_trunc()` and for shorter strings we might need to pad it with whitespace (or other characters) using `str_pad()`. To give a sense of this:

```{r, results='hold'}
str_pad(string = "Danielle", width = 20)
str_pad(string = "Danielle", width = 20, side = "right")
str_pad(string = "Danielle", width = 20, side = "both")
str_pad(string = "Danielle", width = 20, side = "both", pad = "-")
```

```{r, results='hold'}
str_trunc(string = "Danielle", width = 9)
str_trunc(string = "Danielle", width = 8)
str_trunc(string = "Danielle", width = 7)
str_trunc(string = "Danielle", width = 7, ellipsis = "+++")
```

Truncation and padding work very nicely together:

```{r}
input %>% 
  str_pad(width = 7, side = "right") %>%
  str_trunc(width = 7)
```

## Removing whitespace

A common problem when dealing with text is white space that appears in the wrong place. For example, suppose someone intended to type the words *tupim*, *tupin* and *poi* as part of the experiment but ended up with additional spaces, leading to this as the raw data:

```{r}
raw <- "  tupim   tupin    poi    "
```

The `str_trim()` function removes all leading and trailing whitespace; `str_squish()` does the same but also compresses any internal whitespace to a single character. Thus:

```{r, results='hold'}
raw
raw %>% str_trim()
raw %>% str_squish()
```

## Wrapping strings

```{r}
input %>% 
  str_flatten(", ") %>% 
  str_wrap(width = 30, indent = 5, exdent = 3) %>% 
  cat()
```


## Sorting strings

There are a collection of functions that manipulate properties of text that vary from one language to the next. The order in which letters appear in the alphabet isn't always the same, for example. These functions all have a `locale` value that is set to `"en"` by default. 

```{r, results="hold"}
letters %>% str_sort(locale = "en") %>% str_flatten()
letters %>% str_sort(locale = "haw") %>% str_flatten()
```

There is also a `str_order()` function that returns a numeric vector indicating the order in which the original input should be shuffled to produce a sorted output.


## Changing case 

For dealing with upper and lower case:

```{r, results='hold'}
"DANIELLE navarro" %>% str_to_lower()
"DANIELLE navarro" %>% str_to_upper()
"DANIELLE navarro" %>% str_to_title()
```

Note that these are also locale sensitive: the precise mappings that determine what counts as upper and lower case aren't the same in different languages.







## Pattern matching

Many text processing tasks require us to solve *pattern matching* problems. This might be something simple like finding every instance of the word `"hello"` or something more complicated like extracting every email address from a messy web page. The approach taken in **stringr** is to make a conceptual distinction between functions that allow you to perform *tasks*, and functions that specify pattern matching *engines*.

### Tasks

There are many different tasks that you can solve using pattern matching methods and as a result there are many different pattern matching functions. This isn't a complete listing of the functions in **stringr** that you can use for this, but it covers most of the main ones:

- `str_split` breaks a string by a separating character
- `str_count` counts the number of times a string matches a pattern 
- `str_detect` and `str_subset` finds strings that match a pattern
- `str_locate` finds the position of the first pattern match in a string
- `str_locate_all` finds the positions of all matches
- `str_extract` returns the first match in a string (see also `str_match`)
- `str_extract_all` returns all matches in a string (see also `str_match_all`)
- `str_remove` deletes the first part of a string that matches a pattern
- `str_remove_all` deletes all parts of a string that match a pattern
- `str_replace` and `str_replace_all` allow you to make substitutions 

I'll go into a little more detail on these shortly.

### Engines

The thing I really like, though, is the fact that the *engine* that defines what counts as a pattern is broken up into convenience functions:

- A `fixed` pattern is the simplest type: it matches an exact pattern
- A `coll` pattern is similar, but recognises that the same character can be represented in different ways (especially useful if you're using non-English characters)
- A `boundary` pattern can match the breaks between words, lines, characters, or sentences. By convention `""` is used as shorthand for `boundary("character")`
- A `regex` (the default throughout **stringr**) is a regular expression

I'll start out giving an example that uses `boundary`, but for the most part I'll use `fixed` expressions. I'll leave regular expressions for the very end - they're easily the most powerful tool but also the most complicated.

## Splitting strings

To give a sense of how we might want to use `str_split()` to break up strings, let suppose I want to take the start of *Pride and Prejudice* and split it up by word, character, or sentence. First, I'll need to define it:

```{r}
truth <- "It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife. However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters."
```

Now, if I want to break this up, the *task* I need to solve is governed by the `str_split()` function, but the three goals I've set myself all relate to a `boundary()` pattern of some kind, so that's the *engine* I'll use. So the commands I need here would be:

```{r,results='hold'}
truth %>% str_split(pattern = boundary("word"))
truth %>% str_split(pattern = boundary("character"))
truth %>% str_split(pattern = boundary("sentence"))
```

## Count, detect, subset

Suppose I would like to look at the presence of the string `"ni"` within each of the 
`input` words. It's a specific piece of text, so we'll use `fixed("ni")` to specify the pattern. There are a few different tasks we might want to complete. We could count the *number* of times `"ni"` appears in every word (a job for `str_count`), we could ask *whether* the string `"ni"` appears in each word (a job for `str_detect`), or we could ask *which* of the words contain `"ni"`. That leads to the following commands: 

```{r}
input %>% str_count(pattern = fixed("ni"))
input %>% str_detect(pattern = fixed("ni"))
input %>% str_subset(pattern = fixed("ni"))
```

## Locate

```{r}
"gepinini" %>% str_locate(fixed("ni"))
"gepinini" %>% str_locate_all(fixed("ni"))
```



## Extract, remove, replace

The last group of pattern matching functions I want talk about are those that *extract*, *remove* or *replace* parts of strings that match a pattern. To get the most out of these functions, it's useful to switch to *regular expressions* to define patterns. Regular expressions are complicated things and I won't even try to do anything but the most basic tasks with the. To start with, consider this:
```{r}
vowels <- regex("[aeiouAEIOU]")
```
Setting aside the details of how it works, you might guess that this is an expression that matches vowels. So if we take the opening passage to *Pride and Prejudice* and do this

```{r}
truth %>% str_remove_all(pattern = vowels) 
```

we end up with output that removes all the vowels. Alternatively, we could replace all the vowels with periods using this command

```{r}
truth %>% str_replace_all(pattern = vowels, replacement = fixed(".")) 
```

Finally, we could use a command like this to extract all the vowels from `truth`:

```{r}
truth %>% str_extract_all(pattern = vowels) 
```

## Regular expressions

- quick intro here

## An example

Okay, so now I should be able to do neat things with the whole novel. Let's start by gluing the `pp` vector into one long string, since the line breaks don't seem to appear at any interesting locations

```{r}
pp <- janeaustenr::prideprejudice %>%
  str_flatten(" ") %>%
  str_squish
```

Okay, so now I want to give myself something to *do* with this. I'm tired and sick and I can't think of anything clever, so I'll just try and locate every appearance of the words `"Elizabeth"`, `"Darcy"` and `"Wickham"` in the text:
```{r}
characters <- regex("Elizabeth|Darcy|Wickham")
x <- pp %>% str_extract_all(characters) 
y <- pp %>% str_locate_all(characters) 
df <- tibble(character = x[[1]], location = y[[1]][,1] / str_length(pp))
df %>% ggplot(aes(x = location)) +
  facet_wrap(~ character) +
  geom_histogram(bins = 5)
```

No surprises there: `Elizabeth` occurs most frequently, and at the most uniform rate. At the start of the book `Darcy` appears just as often, but then there are sections of the book that don't concern him and the function flatlines for a while. `Wickham` is absent more often than not.


## More resources

- The [stringr](https://stringr.tidyverse.org/) package
- The glue package
- [Text Mining with R](https://www.tidytextmining.com/) by Julia Silge and David Robinson

