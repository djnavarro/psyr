<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Backpropagation networks</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<!-- ###### start inserted header ##### -->

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-115940772-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-115940772-1');
</script>

<!-- add the twitter card and open graph tags -->
<meta name="twitter:card" content="summary">
<meta name="twitter:creator" content="@djnavarro">
<meta property="og:url" content="http://compcogscisydney.org/psyr/">
<meta property="og:title" content="R for Psychological Science">
<meta property="og:description" content="An introductory resource">
<meta property="og:image" content="http://compcogscisydney.org/psyr/img/splash_turtle.png">

<!-- ###### end inserted header ##### -->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="mystyle.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 60px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 65px;
  margin-top: -65px;
}

.section h2 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h3 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h4 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h5 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h6 {
  padding-top: 65px;
  margin-top: -65px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">R for Psychological Science</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Core
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="getting-started.html">Getting started</a>
    </li>
    <li>
      <a href="variables.html">Variables</a>
    </li>
    <li>
      <a href="scripts.html">Scripts</a>
    </li>
    <li>
      <a href="packages.html">Packages</a>
    </li>
    <li>
      <a href="workspaces.html">Workspaces</a>
    </li>
    <li>
      <a href="vectors.html">Vectors</a>
    </li>
    <li>
      <a href="loops.html">Loops</a>
    </li>
    <li>
      <a href="branches.html">Branches</a>
    </li>
    <li>
      <a href="functions.html">Functions</a>
    </li>
    <li>
      <a href="programming.html">Programming</a>
    </li>
    <li>
      <a href="file-system.html">File system</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Data
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="prelude-to-data.html">Prelude</a>
    </li>
    <li>
      <a href="data-types.html">Data types</a>
    </li>
    <li>
      <a href="describing-data.html">Describing data</a>
    </li>
    <li>
      <a href="visualising-data.html">Visualising data</a>
    </li>
    <li>
      <a href="manipulating-data.html">Manipulating data</a>
    </li>
    <li>
      <a href="working-with-text.html">Text data</a>
    </li>
    <li>
      <a href="import-export.html">Import/export</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Stats
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="probability.html">Probability distributions</a>
    </li>
    <li>
      <a href="introductory-statistics.html">Introductory statistics</a>
    </li>
    <li>
      <a href="intermediate-statistics.html">Intermediate statistics</a>
    </li>
    <li>
      <a href="advanced-statistics.html">Advanced statistics</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    More
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="experiments.html">Experiments</a>
    </li>
    <li>
      <a href="shiny.html">Shiny apps</a>
    </li>
    <li>
      <a href="web-scraping.html">Web scraping</a>
    </li>
    <li>
      <a href="xx-miscellaneous.html">Miscellaneous</a>
    </li>
    <li>
      <a href="backprop.html">Backpropagation networks</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://compcogscisydney.org">compcogscisydney.org</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Backpropagation networks</h1>

</div>


<p>Earlier in these notes I used the <a href="./programming.html">Rescorla-Wagner</a> model of associative learning as an example of how to implement computational models of cognition in R. In this and later sections, I’ll expand the dicussion of models to cover a variety of other models in the field. I’ll start with the <strong>backpropagation rule</strong> for learning in connectionist networks.</p>
<div id="scripts-and-data-set" class="section level2">
<h2><span class="header-section-number">0.1</span> Scripts and data set</h2>
<ul>
<li>The <a href="./data/iris_recode.csv">iris_recode.csv</a> file contains the classic iris data slightly reorganised as purely numeric data (<a href="./scripts/iris_recode.R">here</a>) is the script that generated it.</li>
<li>The first version of the modelling code implements a simple two-layer backpropagation network for the iris data: <a href="./scripts/iris_twolayer.R">iris_twolayer.R</a></li>
<li>The second version of the code implements the same model, but expressing the learning rules as matrix operations in order to speed up the calculations: <a href="./scripts/iris_twolayer2.R">iris_twolayer2.R</a></li>
</ul>
<p>At the moment the scripts don’t do anything other than learn a classification rule. The goal for the full exercise will (eventually) be to examine what the model is learning across the series of “epochs”, and consider the relationship between this connectionist network and a probabilistic logistic regression model, but for now it’s a bit simpler than that!</p>
<p>In this tutorial we’ll only cover a very simple version of a backpropagation network, the two-layer “perceptron” model. There are two versions of the code posted above. The code in the <a href="./scripts/iris_twolayer.R">iris_twolayer.R</a> script is probably the more intuitive version, as it updates the association weights one at a time, but R code runs much faster when you express the learning rule using matrix operations, which is hwat the <a href="./scripts/iris_twolayer2.R">iris_twolayer2.R</a> version does. Let’s start with a walk through of the more intuitive version…</p>
</div>
<div id="input-and-output-patterns" class="section level2">
<h2><span class="header-section-number">0.2</span> Input and output patterns</h2>
<p>First, let’s take a look at the training data. I’m going to use the classic “iris” data set that comes bundled with R, but I’ve reorganised the data in a form that is a little bit more useful for thinking about the learning problem involved, and expressed it as a numeric matrix.</p>
<pre class="r"><code>irises &lt;- read_csv(&quot;./data/iris_recode.csv&quot;) %&gt;% as.matrix()</code></pre>
<pre><code>## Parsed with column specification:
## cols(
##   sepal_length = col_double(),
##   sepal_width = col_double(),
##   petal_length = col_double(),
##   petal_width = col_double(),
##   context = col_integer(),
##   species_setosa = col_integer(),
##   species_versicolor = col_integer(),
##   species_virginica = col_integer()
## )</code></pre>
<p>This data set has columns containing many features. First there are the <em>input features</em>, which consist of two features relating to the petals, two features relating to the sepal, and a context feature that is 1 for every flower. Additionally, there are three binary valued <em>output features</em> corresponding to the species of each flower, dummy coded so that only the correct species has value 1 and the incorrect species have value 0. Here are the names:</p>
<pre class="r"><code>input_names &lt;- c(&quot;sepal_length&quot;, &quot;sepal_width&quot;, &quot;petal_length&quot;, &quot;petal_width&quot;, &quot;context&quot;)
output_names &lt;- c(&quot;species_setosa&quot;, &quot;species_versicolor&quot;, &quot;species_virginica&quot;)</code></pre>
<p>So for the first flower, the network would be given this pattern as input:</p>
<pre class="r"><code>input &lt;- irises[1, input_names]
input</code></pre>
<pre><code>## sepal_length  sepal_width petal_length  petal_width      context 
##          5.1          3.5          1.4          0.2          1.0</code></pre>
<p>and we need to train it to produce this <em>target pattern</em> as the output:</p>
<pre class="r"><code>target &lt;- irises[1, output_names]
target </code></pre>
<pre><code>##     species_setosa species_versicolor  species_virginica 
##                  1                  0                  0</code></pre>
</div>
<div id="connection-weights-between-input-and-output" class="section level2">
<h2><span class="header-section-number">0.3</span> Connection weights between input and output</h2>
<p>In its simplest form we can describe the knowledge possessed by our network as a set of associative strengths between every input feature and every output feature. In that sense we can think of it as a generalisation of how the Rescorla-Wagner model represents knowledge:</p>
<pre class="r"><code>n_input &lt;- length(input_names)
n_output &lt;- length(output_names)
n_weights &lt;- n_input * n_output</code></pre>
<p>So what we’ll do is create a <em>weight matrix</em> that sets the initial associative strength to zero, with a tiny bit of random noise added to each of these associative weights:</p>
<pre class="r"><code>weight &lt;- matrix(
  data = rnorm(n_weights) *.01,
  nrow = n_input,
  ncol = n_output,
  dimnames = list(input_names, output_names)
)
weight</code></pre>
<pre><code>##              species_setosa species_versicolor species_virginica
## sepal_length  -0.0006319492       -0.020747209      -0.009599228
## sepal_width   -0.0015100447        0.012470262       0.017131124
## petal_length  -0.0019515272        0.002459665      -0.007272674
## petal_width    0.0049298408        0.002108018       0.006111287
## context        0.0151908952        0.008725164      -0.009562111</code></pre>
<p>Here’s the network we want to code:</p>
<div class="figure">
<img src="img/backprop_irises.png" />

</div>
<p>While we’re at it, store a copy for later:</p>
<pre class="r"><code>old_weight &lt;- weight</code></pre>
</div>
<div id="making-predictions" class="section level2">
<h2><span class="header-section-number">0.4</span> Making predictions</h2>
<p>In the Rescorla-Wagner model, when the learner is shown a compound stimulus with elements A and B with individual associative strengths <span class="math inline">\(v_A\)</span> and <span class="math inline">\(v_B\)</span>, the association strength for the compound AB is assumed to be additive <span class="math inline">\(v_{AB} = v_{A} + v_{B}\)</span>. We could do this for our backpropagation network too, but it is much more common to assume a logistic activation function. So we’ll need to define this activation function:</p>
<pre class="r"><code>logit &lt;- function(x){
  y &lt;- 1/(1 + exp(-x))
  return(y)
}</code></pre>
<p>So what we do is first take the <code>sum</code> of the inputs and then pass them through our new <code>logit</code> function. So let’s say we want to compute the strength associated with the first species:</p>
<pre class="r"><code>output_1 &lt;- sum(input * weight[,1]) %&gt;% logit() 
output_1</code></pre>
<pre><code>## [1] 0.5012342</code></pre>
<p>More generally though we can loop over the three species:</p>
<pre class="r"><code># initialise the output nodes at zero
output &lt;- rep(0, n_output)
names(output) &lt;- output_names

# feed forward to every output node by taking a weighted sum of
# the inputs and passing it through a logit function
for(o in 1:n_output) {
  output[o] &lt;- sum(input * weight[,o]) %&gt;% logit() 
}

# print the result
output</code></pre>
<pre><code>##     species_setosa species_versicolor  species_virginica 
##          0.5012342          0.4876089          0.4981203</code></pre>
<p>As you can see, initially the model has no knowledge at all! It’s predicting a value of about 0.5 for every category!</p>
</div>
<div id="learning-from-error" class="section level2">
<h2><span class="header-section-number">0.5</span> Learning from error</h2>
<p>The prediction error is very familiar:</p>
<pre class="r"><code>prediction_error &lt;- target - output
prediction_error</code></pre>
<pre><code>##     species_setosa species_versicolor  species_virginica 
##          0.4987658         -0.4876089         -0.4981203</code></pre>
<p>Here is the code implementing the learning rule. What we’re doing is looping over every weight in the network, and then adjusting the strength proportional to the prediction error:</p>
<pre class="r"><code>learning_rate &lt;- .1

# for each of the weights connecting to an output node...
for(o in 1:n_output) {
  for(i in 1:n_input) {
    
    # associative learning for this weight scales in a manner that depends on
    # both the input value and output value. this is similar to the way that
    # Rescorla-Wagner has CS scaling (alpha) and US scaling (beta) parameters
    # but the specifics are slightly different (Equation 5 &amp; 6 in the paper)
    scale_io &lt;- input[i] * output[o] * (1-output[o]) 
    
    # adjust the weights proportional to the error and the scaling (Equation 8)
    weight[i,o] &lt;- weight[i,o] + (prediction_error[o] * scale_io * learning_rate)
    
  }
}</code></pre>
<p>(Let’s not worry too much about the <code>scale_io</code> factor for now). So let’s look at the input, output, target, and prediction error:</p>
<pre class="r"><code>input</code></pre>
<pre><code>## sepal_length  sepal_width petal_length  petal_width      context 
##          5.1          3.5          1.4          0.2          1.0</code></pre>
<pre class="r"><code>output</code></pre>
<pre><code>##     species_setosa species_versicolor  species_virginica 
##          0.5012342          0.4876089          0.4981203</code></pre>
<pre class="r"><code>target</code></pre>
<pre><code>##     species_setosa species_versicolor  species_virginica 
##                  1                  0                  0</code></pre>
<pre class="r"><code>prediction_error</code></pre>
<pre><code>##     species_setosa species_versicolor  species_virginica 
##          0.4987658         -0.4876089         -0.4981203</code></pre>
<p>Now let’s look at how the weights changed:</p>
<pre class="r"><code>weight - old_weight</code></pre>
<pre><code>##              species_setosa species_versicolor species_virginica
## sepal_length    0.063592258       -0.062131952      -0.063509444
## sepal_width     0.043641746       -0.042639575      -0.043584913
## petal_length    0.017456698       -0.017055830      -0.017433965
## petal_width     0.002493814       -0.002436547      -0.002490566
## context         0.012469070       -0.012182736      -0.012452832</code></pre>
<p>Not surprisingly everything to setosa has gone up and the others down. But notice the scale!</p>
</div>
<div id="visualising-the-learning" class="section level2">
<h2><span class="header-section-number">0.6</span> Visualising the learning</h2>
<p>For the actual simulation I’ll set the learning rate to .01, run it for 5000 epochs and average across 100 independent runs just to smooth out any artifacts of randomisation<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> How the weights change over epochs:</p>
<!-- NOTE:
ffmpeg -i backpropweights.webm backpropweights.gif -hide_banner
ffmpeg -i backpropweights.webm backpropweights.mp4 -hide_banner
-->
<video width="800" style="display:block; margin: 0 auto;" controls>
<source src="./img/backpropweights.webm" type="video/webm">
<source src="./img/backpropweights.mp4" type="video/mp4">
<p>Your browser does not support the video tag </video> <br></p>
</div>
<div id="resources" class="section level2">
<h2><span class="header-section-number">0.7</span> Resources</h2>
<ul>
<li>The Rumelhart et al (1986) paper cached for teaching purposes <a href="http://compcogscisydney.org/mm/2018/Rumelhart1986.pdf">here</a></li>
<li>A very good, but somewhat technical <a href="http://neuralnetworksanddeeplearning.com/chap2.html">summary</a> of backpropagation by Michael Nielsen</li>
<li>Really nice <a href="http://neuroplausible.com/connectionism">resources</a> in Python by Olivia Guest.</li>
</ul>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>The script to run it is <a href="./scripts/iris_twolater3.R">here</a>, a csv with the connections weights is <a href="./output/iris_weights.csv">here</a>, another one (36Mb) with sum squared error to each item on each presentation <a href="./output/iris_sse.csv">here</a>, zipped version (11Mb) <a href="./output/iris_sse.csv.zip">here</a><a href="#fnref1">↩</a></p></li>
</ol>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
